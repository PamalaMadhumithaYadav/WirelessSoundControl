{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f73bf157-323c-4a41-8ff7-8eeb8ec8f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (4.11.0.86)\n",
      "Requirement already satisfied: mediapipe in /opt/anaconda3/lib/python3.12/site-packages (0.10.21)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: absl-py in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (2.2.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (25.2.10)\n",
      "Requirement already satisfied: jax in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.6.1)\n",
      "Requirement already satisfied: jaxlib in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.6.1)\n",
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (3.10.1)\n",
      "Requirement already satisfied: opencv-contrib-python in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.11.0.86)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (4.25.8)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/anaconda3/lib/python3.12/site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Requirement already satisfied: ml_dtypes>=0.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in /opt/anaconda3/lib/python3.12/site-packages (from jax->mediapipe) (1.15.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.12/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python mediapipe numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51a02932-ab93-41d3-ac77-e70a97dc9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import math\n",
    "import numpy as np\n",
    "import subprocess # For macOS audio control\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f24ad9b-b6e9-4d43-b4c7-d7507ed3e4d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1751163399.737446  140327 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 89.4), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "mp_solutions = mp.solutions\n",
    "mp_hands = mp_solutions.hands\n",
    "mp_draw = mp_solutions.drawing_utils\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.7, max_num_hands=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "947e12ec-27f7-4610-94fe-78a41832ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# def list_cameras():\n",
    "#     i = 0\n",
    "#     while True:\n",
    "#         cap = cv2.VideoCapture(i)\n",
    "#         if not cap.read()[0]: \n",
    "#             break\n",
    "#         else:\n",
    "#             print(f\"Camera found at index {i}\")\n",
    "#             cap.release() \n",
    "#         i += 1\n",
    "#     if i == 0:\n",
    "#         print(\"No cameras found. Check connections and permissions.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     list_cameras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6971978-01dc-4d27-9b34-1aabb2270d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-28 22:16:44.593 python[4315:140327] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream. Make sure your webcam is connected and accessible.\")\n",
    "    print(\"If you are on macOS, you might need to grant camera permissions in System Settings > Privacy & Security > Camera.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18728b5e-02cb-49ba-84ba-83f79794596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_volume_percentage = 0 \n",
    "prev_volume_percentage = 0 \n",
    "smoothing_factor = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a42f468-4a21-4341-8533-591a5560a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mute Control Variables\n",
    "last_mute_action_time = 0\n",
    "mute_cooldown_duration = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ada2bf9f-7c7a-4fb6-b14a-5efd53c37ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gesture Confirmation Visuals Variables\n",
    "confirmation_center = None\n",
    "confirmation_color = None\n",
    "confirmation_end_time = 0\n",
    "confirmation_duration = 0.3  # seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dbd8d93-d5f7-4e39-adca-44593ccc346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finger_extended(tip_y, pip_y, threshold=0.03):\n",
    "    # Tip is \"higher\" (smaller y-value) than PIP for an extended finger\n",
    "    return tip_y < pip_y - threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "932df01a-b421-4d69-a442-70b050e25f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finger_curled(tip_y, pip_y, threshold=0.03):\n",
    "    # Tip is \"lower\" (larger y-value) than PIP for a curled finger\n",
    "    return tip_y > pip_y + threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e7d3d8-5651-4b1d-907f-4aef07339f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_mute_status_macos():\n",
    "    try:\n",
    "        output = subprocess.check_output([\"osascript\", \"-e\", \"output muted of (get volume settings)\"]).decode(\"utf-8\").strip()\n",
    "        return output == \"true\"\n",
    "    except Exception as e:\n",
    "        # print(f\"DEBUG: Error getting mute status: {e}\") \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "536a7445-65a1-4fc6-b312-299cbf679906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_system_mute_status_macos(mute_state):\n",
    "    try:\n",
    "        subprocess.call([\"osascript\", \"-e\", f\"set volume output muted {str(mute_state).lower()}\"])\n",
    "        print(f\"DEBUG: osascript mute command sent: {mute_state}\") # Confirm command was sent\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to send mute command via osascript: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c3310fe-5fba-4b61-b97f-f0543e08fb93",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 115\u001b[0m\n\u001b[1;32m    111\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mcircle(frame, confirmation_center, \u001b[38;5;241m20\u001b[39m, confirmation_color, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    113\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGesture Volume & Mute Control (macOS)\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m--> 115\u001b[0m key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m27\u001b[39m:\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to grab frame.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    h, w, c = frame.shape\n",
    "\n",
    "    # --- Instructional Text (Top Right) ---\n",
    "    instruction1 = \"Open Palm to Mute\"\n",
    "    instruction2 = \"Peace Sign to Unmute\"\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    font_scale = 2\n",
    "    color = (0, 0, 0)\n",
    "    thickness = 2\n",
    "    (w1, h1), _ = cv2.getTextSize(instruction1, font, font_scale, thickness)\n",
    "    (w2, h2), _ = cv2.getTextSize(instruction2, font, font_scale, thickness)\n",
    "    margin = 30\n",
    "    pos1 = (w - w1 - margin, margin + h1)\n",
    "    pos2 = (w - w2 - margin, margin + h1 + h2 + 20)\n",
    "    cv2.putText(frame, instruction1, pos1, font, font_scale, color, thickness)\n",
    "    cv2.putText(frame, instruction2, pos2, font, font_scale, color, thickness)\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    is_muted = get_system_mute_status_macos()\n",
    "    mute_status_text = \"Muted\" if is_muted else \"Unmuted\"\n",
    "    cv2.putText(frame, f'Status: {mute_status_text}', (50, 80), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0) if is_muted else (0, 0, 0), 2)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_draw.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            # drawing a line between thumb and index finger\n",
    "            thumb_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_MCP]\n",
    "            index_finger_mcp = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "            thumb_point = (int(thumb_mcp.x * w), int(thumb_mcp.y * h))\n",
    "            index_point = (int(index_finger_mcp.x * w), int(index_finger_mcp.y * h))\n",
    "            cv2.line(frame, thumb_point, index_point, (224, 224, 224), 2)\n",
    "          \n",
    "\n",
    "            # Volume Control Logic\n",
    "            thumb_tip = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "            index_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "            x1, y1 = int(thumb_tip.x * w), int(thumb_tip.y * h)\n",
    "            x2, y2 = int(index_tip.x * w), int(index_tip.y * h)\n",
    "            length = math.hypot(x2 - x1, y2 - y1)\n",
    "            min_hand_length, max_hand_length = 30, 200\n",
    "\n",
    "            target_volume_percentage = np.interp(length, [min_hand_length, max_hand_length], [0, 100])\n",
    "            current_volume_percentage = (smoothing_factor * current_volume_percentage) + ((1 - smoothing_factor) * target_volume_percentage)\n",
    "\n",
    "            if abs(current_volume_percentage - prev_volume_percentage) > 2:\n",
    "                if not is_muted:\n",
    "                    subprocess.call([\"osascript\", \"-e\", f\"set volume output volume {int(current_volume_percentage)}\"])\n",
    "                prev_volume_percentage = current_volume_percentage\n",
    "\n",
    "            cv2.putText(frame, f'Vol: {int(current_volume_percentage)}%', (50, 50), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 0), 2)\n",
    "\n",
    "            # Customizable Volume Bar\n",
    "            bar_height = int(np.interp(current_volume_percentage, [0, 100], [400, 150]))\n",
    "            cv2.rectangle(frame, (50, 150), (85, 400), (0, 0, 0), 3) # Outline\n",
    "            cv2.rectangle(frame, (50, bar_height), (85, 400), (255, 255, 255), -1) # Fill\n",
    "            cv2.putText(frame, \"100%\", (40, 140), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            cv2.putText(frame, \"0%\", (45, 415), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "            # Mute/Unmute Gesture Detection Logic\n",
    "            current_time = time.time()\n",
    "            if current_time - last_mute_action_time > mute_cooldown_duration:\n",
    "                thumb_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y\n",
    "                thumb_ip_y = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_IP].y\n",
    "                index_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y\n",
    "                index_pip_y = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_PIP].y\n",
    "                middle_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y\n",
    "                middle_pip_y = hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_PIP].y\n",
    "                ring_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_TIP].y\n",
    "                ring_pip_y = hand_landmarks.landmark[mp_hands.HandLandmark.RING_FINGER_PIP].y\n",
    "                pinky_tip_y = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].y\n",
    "                pinky_pip_y = hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_PIP].y\n",
    "\n",
    "                is_full_open_palm = (finger_extended(thumb_tip_y, thumb_ip_y) and\n",
    "                                     finger_extended(index_tip_y, index_pip_y) and\n",
    "                                     finger_extended(middle_tip_y, middle_pip_y) and\n",
    "                                     finger_extended(ring_tip_y, ring_pip_y) and\n",
    "                                     finger_extended(pinky_tip_y, pinky_pip_y))\n",
    "                is_peace_sign = (finger_extended(index_tip_y, index_pip_y) and\n",
    "                                 finger_extended(middle_tip_y, middle_pip_y) and\n",
    "                                 finger_curled(ring_tip_y, ring_pip_y) and\n",
    "                                 finger_curled(pinky_tip_y, pinky_pip_y))\n",
    "\n",
    "                if is_full_open_palm and not is_muted:\n",
    "                    set_system_mute_status_macos(True)\n",
    "                    last_mute_action_time = time.time()\n",
    "                    confirmation_center = (int(np.mean([lm.x * w for lm in hand_landmarks.landmark])), int(np.mean([lm.y * h for lm in hand_landmarks.landmark])))\n",
    "                    confirmation_color = (0, 0, 255) # Red for mute\n",
    "                    confirmation_end_time = time.time() + confirmation_duration\n",
    "\n",
    "                elif is_peace_sign and is_muted:\n",
    "                    set_system_mute_status_macos(False)\n",
    "                    last_mute_action_time = time.time()\n",
    "                    confirmation_center = (int(np.mean([lm.x * w for lm in hand_landmarks.landmark])), int(np.mean([lm.y * h for lm in hand_landmarks.landmark])))\n",
    "                    confirmation_color = (0, 255, 0) # Green for unmute\n",
    "                    confirmation_end_time = time.time() + confirmation_duration\n",
    "\n",
    "    # Draw Gesture Confirmation Circle\n",
    "    if confirmation_center and time.time() < confirmation_end_time:\n",
    "        cv2.circle(frame, confirmation_center, 20, confirmation_color, -1)\n",
    "\n",
    "    cv2.imshow(\"Gesture Volume & Mute Control (macOS)\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q') or key == ord('Q') or key == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af097ba8-a2d0-4c9f-ada9-426b57cbba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6f599169-b13a-4986-b714-fb872de04337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224140a7-ee49-43cc-b022-fce12b36c84b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
